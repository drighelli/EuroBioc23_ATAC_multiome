---
title: "Differential Accessible Regions analysis of single-cell 10X Genomics multiome data"
author: "Dario Righelli"
date: "`r Sys.Date()`"
output: 
    BiocStyle::html_document:
        toc: false
    vignette: >
      %\VignetteIndexEntry{Differential Accessible Regions analysis of single-cell 10X Genomics multiome data}
      %\VignetteEncoding{UTF-8}
      %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

# Requirements

```{r reqs, message=FALSE}
library(TENxMultiomeTools)
library(AllenInstituteBrainData)
library(Signac)
library(Seurat)
library(EnsDb.Mmusculus.v79)
library(scuttle)
library(scater)
library(darioscripts)
```

# Introduction

The `TENxMultiomeTools` package is a work in progress project intended to 
facilitate the loading and handling of 10x Genomics multiome data in a
`SingleCellExperiment` format.

This pipeline starts from the output generated by the 10x cellranger-ARC 
pipeline and is designed for differential analysis of multiple samples in 
different conditions.
We defined it while working on a complex design of 12 different multiome samples
of mouse brain cortex in 4 different condition.

Because the data are not published yet, we are using one of the publicly 
available dataset from the official 10x Genomics website to illustrate the 
available functionalities of the package and challanges faced with this type of
data.

Additionally, because of lack of public datasets with different conditions, we
cannot illustrate the full pipeline, but we'll go through the implemented
functionalities and we'll illustrate possible examples on real data.

We used two replicates of the same mouse brain tissue present on the official 
[10x Genomics Website](https://www.10xgenomics.com/resources/datasets?query=&page=1&configure%5BhitsPerPage%5D=50&configure%5BmaxValuesPerFacet%5D=1000&refinementList%5Bproduct.name%5D%5B0%5D=Single%20Cell%20Multiome%20ATAC%20%2B%20Gene%20Expression&refinementList%5Bspecies%5D%5B0%5D=Mouse&refinementList%5BanatomicalEntities%5D%5B0%5D=cortex).

# Loading Data

To facilitate 10x Genomics Multiome data loading we can use the `read10xMultiome` 
function, which takes the following parameters as input:

+ `sample_path`: the path of the experiment
+ `type`: the type of data to load, sparse/hdf5
+ `data`: data type to load, filtered/raw
+ `compressed`: logical indicating if the data are stored in a compressed format
+ `col.names`: logical indicating if to add ID to the cols of the assays.
+ `addfrags`: logical indicating if the path to the fragments file has to be 
saved in the sce.  Note that this is needed when computing the metrics in the 
next step.
+ `reference`: character indicating the reference assay to use as main assay

This function loads the data in a `SingleCellExperiment` format, creating a `main`
assay and an `altExp` assay, which is another `SingleCellExperiment` object.
The `colData` of the main assay will always contain the information related to the
cells of the experiment, so it will not be replicated twice, but only stored in
the main one.
On the other hand the information related to the rows of the assays differ because
for the RNA a `rowData` `DataFrame` stores information about the genes, while for 
the ATAC data it will be in a `rowRanges` format. This format allows to store the
information about the peaks in a `GenomicRanges` format where the genomic
coordinates are in the form of Chromosome, Start and End while additional data 
are stored in the `mcols` `DataFrame.`

N.B. The `read10xMultiome` function will be deprecated in favor of the 
exported functionalities of the `TENxIO` package.

```{r read10x, eval=FALSE}
library(TENxMultiomeTools)
scelist <- lapply(c("multiome_website_mouse_old", 
                    "multiome_website_mouse_old_rep2"),    
                read10xMultiome, 
                type="HDF5", 
                addfrags=TRUE)

names(scelist) <- c("Brain_R1", "Brain_R2")
saveRDS(scelist, "RDS/scelist_10xBrain.RDS")
```


```{r loadata}
scelist <- readRDS("RDS/scelist_10xBrain.RDS")
sce <- scelist[[1]]
sce
colData(sce)
rowData(sce)
altExp(sce)
rowRanges(altExp(sce))
```


# Create Annotation

The 10x Multiome default output comes with an `annotation` file for the detected
genes, but this file could be very heavy to store in memory and to manipulate.
A way to avoid this is to create an annotation by aid of an EnsDb package, which
downloads the annotation data for an entire genome.

```{r annotation, message=FALSE, warning=FALSE}
library(Signac)
library(Seurat)
library(EnsDb.Mmusculus.v79)
ensdb <- EnsDb.Mmusculus.v79
seqlevelsStyle(ensdb) <- "UCSC"
annotation <- GetGRangesFromEnsDb(ensdb = ensdb)
genome(annotation) <- "mm10"
```


# Quality Control

Once that we have the data loaded and an annotation object in GenomicRanges format,
we can start by computing some quality control metrics.

At the moment we defined three quality controls approaches, the Signac metrics, 
the `scuttle::isOutlier` and the doublets detection implemented in the 
`scDblFinder` package, but we'll focus on the Signac metrics for this tutorial.

## Signac Metrics

At the moment we implemented a wrapper for the Signac package (available on CRAN),
which allows to compute multiple metrics both on RNA and ATAC data.

The metrics computed by `Signac` are defined as follows: 

+ number of counts per each gene for the RNA and each feature for the ATAC
+ the number of features on the RNA
+ computing the ratio of fragments between 147 bp and 294 bp (mononucleosome) 
to fragments < 147 bp (nucleosome-free)
+ computing the TSS enrichment score as defined by *Encode*: 
    + normalized score on the number of reads around (2000bp up/down) the TSS 

```{r metrics, eval=FALSE}
scelist <- lapply(scelist, computeSignacMetrics, annotation)

saveRDS(scelist, file="RDS/scelist_metrics.RDS")
```


## Compute filters on the previous metrics

Once we have the `Signac` metrics computed, we can use them to filter-out 
low-quality cells.
To do so, we decided to compute the quantiles of the distribution of each 
metric.

We defined the low-quality cells as the ones that have at the same time all these
checks passed:
+ number of counts per genes and features lower than the lowest quantile 
(default 5%) and higher than the highest quantile (default 95%).
+ number of features on the RNA lower than the lowest quantile (default 5%) 
and higher than the highest quantile(default 95%).
+ nucleosome signal lower than 2
+ TSS enrichment lower that 1

We can choose this thresholds by hand with the `lowQuantThr`, `highQuantThr`, 
`nucleosomeThr` and `TSSThr`, parameters in the `computeFilterCellsMetrics` 
function.

Of course the default parameters can be chosen with an heuristic approach.

```{r filtermetr}
scelist <- readRDS("RDS/scelist_metrics.RDS")
scelist <- lapply(scelist, function(sce)
{
    computeFilterCellsMetrics(sce, metric="quantile",
        lowQuantThr="5%", highQuantThr="90%",
        nucleosomeThr=2, TSSThr=1)
})
```

## Quality Control Plots

We can take a look to the distributions and the labeled cells with the 
`plotFilteredCells` function, which shows violin plots for all the metrics 
computed and colors the cells based on the quality control passed/not passed 
label.

The arguments of this function allow to plot the filtered-in/out cells with the 
`inout` parameter. Of course we are mainly interested in the filtered-out cells
because we want to better understand if there is something important the we're
filtering out.

It is also possible to pass a custom column with a user-defined column name 
with `TRUE`/`FALSE` values indicating the kept/filtered cells, by aid of the
`filterCellsBy` and `customColName` parameters.

```{r plot_filt_cells}
for(sce in scelist)
{
    print(plotFilteredCells(sce, name="Signac Metrics", inout="out"))
}
```

## Filtering Cells

Once we retain satisfied with the Quality Controls we can proceed by filtering
the cells and to normalize the data.

We highlight that the `in_signac` column is automatically computed in the 
`computeFilterCellsMetrics` and it is a logical `AND` across all the metrics 
described in the previous "Signac" steps.

```{r}
scelist <- lapply(scelist, function(sce) {
    sce <- sce[,sce$in_signac]
    sce <- logNormCounts(sce)
    sce <- runPCA(sce)
    sce <- runTSNE(sce, dimred="PCA")
    sce
})
```


# Assign Cell Labels

To assign cell labels there are several methods available in literature, some of
which requires a reference dataset which helps to map the cell labels from the
reference to our dataset.

At the moment there are not so many reliable reference dataset easisly available,
in particular with validated cell types and, obviously, not for any kind of tissue
we could need.

## Cell Types Reference

For this tutorial, we are using a reference dataset from the Allen Institute, 
available from the `AllenInstituteBrainData` package [https://github.com/drighelli/AllenInstituteBrainData](https://github.com/drighelli/AllenInstituteBrainData) 
which allows to download an annotated dataset of ~1 Million mouse brain cells 
annotated at three different levels of taxonomy. 

This reference has three levels of annotation graularity:

+ the cluster level is the level where the cells have been clustered in
+ the subclass level is the level where the cells have been validated thank to cell-type
markers
+ the class level is the level where the cells have been grouped together because
of cell-types belonging to the same cell family.

After downloading the dataset, it could be useful to create pseudo-bulk counts
to speed up our computations.
Using a reference of 1 Million cells could take very long time during the process
of cell type annotation, and from our tests using the pseudo-bulk counts is a 
pretty good approximation in terms of the obtained results.

```{r, eval=FALSE}
allen <- AllenInstituteBrainData("Allen_Mouse_2020")
allen <- aggregateAcrossCells(allen, use.assay.type = "counts",id=DataFrame(label=allen$subclass_label))
allen <- logNormCounts(allen)
saveRDS(allen, "RDS/Allen_pseudo.RDS")
```

We need to map the annotation in the same gene format as our dataset to compute
the cell labels in the next step.

```{r}
allen <- readRDS("RDS/Allen_pseudo.RDS")
```


## Assigning labels to the cells 

At this point we can simply assign the labels from the reference to our 
dataset. 
At the moment, we created a wrapper `assignLabels` around the `SingleR` package, 
but, as already mentioned, there is plenty of methods that can be used for this 
scope.

Indeed, further versions of this function will implement other methods, 
i.e. `Azimuth` from Rahul Satija lab.

```{r, eval=FALSE}
scelist <- lapply(scelist, function(sce) { 
    assignLabels(sce, allen, "subclass_label")
})
saveRDS(scelist, file="RDS/scelist_lblSR.RDS")
```

# Visualizing cell types

Once we have the cell types labeled for our experiment, we are interested in 
understanding their clustering and this can be easily done with the `plotTSNE`
function of the `scater` package.

```{r}
scelist <- readRDS("RDS/scelist_lblSR.RDS")
lapply(scelist, function(sce){table(sce$SingleR)})
lapply(scelist, plotTSNE, colour_by="SingleR")
```


## Doublets

Another Quality Control on the cells can be done by computing doublets scores.
We implemented a wrapper on the `scDblFinder` package, 
because it offers multiple methods for doublets detection.
In particular, the doublet score for each cell is based on the density of 
simulated doublets around it.

Even if the results provided by this package are still under verification,
we suggest to use it to better understand the quality of the cells in the 
experiment.

Actually, we implemented the method for the scRNAseq data, but further 
implementations will take into account methods for scATACseq data and further
investigations need to be done on how to apply these methods on both assays.

```{r, eval=FALSE}
library(scater)
scelist <- lapply(scelist, logNormCounts)
scelist <- lapply(scelist, computeDoublets, method="griffiths")
saveRDS(scelist, file="RDS/scelist_doublets.RDS")
```

It is possible to visualize these results with a simple TSNE plot, but better
investigations can be done when cell types labels will be assigned to our cell 
and looking where the doublets fall in our dataset.

```{r}
scelist <- readRDS(file="RDS/scelist_doublets.RDS")
for(sce in scelist)
{
    sce <- runPCA(sce)
    sce <- runTSNE(sce, dimred="PCA")
    plotTSNE(sce, colour_by="dbl.scores") + theme_bw()
    plotTSNE(sce, colour_by="dbl.calls") + theme_bw()
}
```

We can use this information to remove doublets from the dataset.

```{r}
scelist <- lapply(scelist, function(sce){sce[,sce$dbl.calls=="singlet"]})
```

For teaching purposes, we now subset the celltypes to the ones with the higher 
amount of cells.

```{r}
celltypes <- c("Astro", "Oligo", "CR")
scelist <- lapply(scelist, function(sce){sce[,sce$SingleR %in% celltypes]})
```

# Differential Analysis

We selected two main approaches for doing differential analysis of these data,
by applying muscat (working on single cell data) and by using `edgeR` (working on
bulk data).

Because the second one produced better results on our datasets, we are going to 
illustrate the steps that can be performed to apply edgeR on single cell data
to obtain differentially expressed genes (RNA) and differential accessible 
regions (ATAC).

To apply bulk analysis methods on single cell data, these need to be transformed
in pseudo-bulk counts, and to do so there are multiple methods able to do that.

NB: We are not pointing to not use muscat (or other methods), but to always compare 
the results produced by multiple approaches to better investigate your data.

## Pseudobulk

A possible approach to obtain pseudo-bulk data from your single-cell is to 
use the `aggregateAcrossCells` method from the `scuttle` package
(as previously done for the reference dataset).

To apply this method we simply have to define a named vector of the cell types 
to use for the aggregation of the cells.
In our case, we saved this information in the `colData` of our `SingleCellExperiment`
under the `SingleR` column.

This approach is pretty straightforward when working with a scRNAseq because the
genes are well defined even when working with multiple experiments. 

In the end, we will have a new `SingleCellExperiment` with a reduced number of 
columns, which, in turn, will be of the same number of cell types defined in our
`SingleR` `colData` column.

```{r, eval=FALSE}
scelist <- lapply(scelist, swapAltExp, name="RNA")
scelistps <- lapply(scelist, function(sce){
    applySCE(sce, aggregateAcrossCells, use.assay.type="counts",
        id=DataFrame(label=sce$SingleR))
    })
    
saveRDS(scelistps, "RDS/scelistps_brain.RDS")
```

At this point it is possible to apply and visualize the data like bulk data.

```{r}
scelistps <- readRDS("RDS/scelistps_brain.RDS")

lapply(scelistps, function(sce) {
    plotPCAs(counts(sce), colData=colData(sce), shapeBy="SingleR", 
                colorBy="SingleR")
})
```

# ATAC Analysis

The same operation for pseudo bulk can be made on a single ATAC experiment 
obtaining the same number of columns as for the RNA.

```{r}
scelistps <- lapply(scelistps, swapAltExp, name="ATAC")
counts(scelistps[[1]])
rowRanges(scelistps[[1]])
```


# ATAC Replicates Consensus Peaks

But things become a little bit more complicated when having multiple ATAC
experiments, coming from different conditions,
it could be problematic to compute a pseudo-bulk counts, because of the 
differences across the peaks (each experiment has different number of peaks
and coordinates).

We can use the `DEScan2` already implemented functionalities for bulk 
data, but with some precautions.


# Creating BAM files per cell types

To properly construct a new count matrix with DEScan2 for our consensus peaks, 
we need the BAM files organized per cell types.

We can use the `10xMultiomeTools::createBamCt` function to do this operation.

This function requires a few external software to operate properly:
+ `sinto`: a python software to create BAM files per each cell type starting from 
a list of barcodes (the ones of the specified cell type)
+ `samtools`: useful to sort and index the new BAM files

Parameters Details:

+ `sce`: An SCE object
+ `sampleName`: the name of the sample
+ `cellType`: the name of the cell type to process
+ `cellTypesCol`: the name of che colData colname where to get the cell types 
+ `sort`: it sorts the bam file with `samtools`
+ `bamdir`: the directory where to get the input bams, if you used the 
`read10xMultiome` function this information is stored in the `metadata(sce)$path`
+ `bamType`: one of `ATAC, GEX, both` to process one of the assays or both
+ `outdir`: the new bam output directory (automatically created)
+ `ncores`: the number of cores to use


NB This is not needed if you already have the BAM files organized by cell types.

```{r, eval=FALSE}
scelist <- lapply(scelist, function(sce){
    path <- lapply(unique(sce$SingleR), function(ct){
        createBamCt(sce, cellType=ct, 
            cellTypesCol="SingleR", sort=TRUE,
            bamdir=metadata(sce)$path, bamType="ATAC", 
            outdir="bams_allct", ncores=10)
    })
    metadata(sce)$ct_bams <- unique(unlist(path))
    sce
})
```

# DEScan2 package

The `DEScan2` package was developed to work with genomic bulk data, it implements
three major steps:

+ Peak Calling: `findPeaks` a peak caller for identify the regions present in 
the BAM/BED files of the experiment (not suggested for single cell data)
+ consensus peaks: `finalRegions` given a list of GenomicRanges (GR) identifies the 
common peaks across the given list and returns a new (GR) with the consensus list
of the found peaks.
+ count matrix construction: `countFinalRegions` starting from a GR and a directory
with BAM files, it constructs a new matrix of counts with the peaks on the rows
and the bamfiles (samples) on the column.

## A few details

Before working with these functions we first provide a few details to better 
understand how to setup them:

+ `finalRegions`:
++ `peakSamplesGRangesList`: a GenomicRangesList, each element of the list is a 
GR, associated to a sample. 
++ `zThreshold`: a numeric value allowing to remove all the peaks with a score less
then it. We set this to 0 if we want to keep all the peaks.
++ `minCarriers`: a numeric value allowing to keep all the peaks present at least
in `minCarriers` samples.
++ `scorecolname`: character indicating the name of the column where the peaks 
score are stored.
++ **Returns**: a GR with the consensus peaks and some additional info
+++ `k-carriers`: number of samples where the peak has been found 
(an interval between [`minCarriers`, `length(peakSamplesGRangesList)`])
+++ `n-peaks`: the total number of peaks where the new consensus peak is 
originating from

+ `countFinalRegions`:
++ `regionsGRanges`: a GR, ideally the GR of our consensus peak list, but it can 
be any GR.
++ `readsFilePath`: the `filepath` of BAM or BED files to compute the coverage of the peaks.
++ `fileType`: one of BAM or BED
++ `minCarriers`: same as for `finalRegions`, the minimum number of samples where
the peak needs to be present, otherwise it will be discarded.
++ **Returns**: a `SummarizedExperiment` with the peaks on the `rowRanges` and a 
new matrix of counts on the main assay.

## Working with single cell ATAC data

DEScan2 finalRegions needs a score column for working properly, but when working
with 10x default peaks this score is not provided.

A possible work-around can be done by using the counts/logcounts assay for the 
ATAC data.

By aid of the 10xMultiome `buildATACScores` we are able to create a new score column
in the rowRanges of the SCE and use this column in the DEScan2 finalRegions function.

The score is defined as the sum of the counts of all the Barcodes assigned to a 
specific cell type.

To compute this for all the cell types we include these operations in a loop
over all the celltypes present in the SingleCellExperiments.

```{r, eval=FALSE}
library(DEScan2)

grlct <- lapply(celltypes, function(ct)
{
    grl <- lapply(scelist, function(sce) {
        message("computing atac scores")
        # this function helps to create a score for the CT
        sce <- buildATACScores(sce, cellType=ct)
        rowRanges(altExp(sce))
    }) 
    message("Computing final regions")
    # we now work only with the rowRanges of both the experiments
    gr <- finalRegions(GRangesList(grl), 
        zThreshold=0, minCarriers=1, saveFlag=FALSE, 
        scorecolname="score", verbose=TRUE,
        BPPARAM=BiocParallel::MulticoreParam(workers=1))
    
    ## moving bam in a dedicated folder per each cell type
    bams <- list.files("bams_allct",  pattern="*sorted.bam*", full.names=TRUE)
    bams <- bams[grep(ct, bams)] # just to be sure to take only the ones of the ct
    ctpath <- file.path("bams_allct", ct)
    if(!dir.exists(ctpath)) dir.create(ctpath, showWarnings=FALSE)
    file.rename(bams, file.path(ctpath, basename(bams)))
    metadata(gr)$bam_path <- ctpath
    gr
})
names(grlct) <- celltypes

saveRDS(grlct, file="RDS/grlct_celltypes_brain.RDS")
```

We inspect the number of consensus peaks list present in each celltype to 
compare this information across all the celltypes.
Obviously, in this case the starting samples are the same for all the celltypes 
so we obtain the same number of peaks. 
This changes when we work with samples of different conditions.

The main aim of this plot is to understand how many peaks we have across the 
samples present in our experiment.

Typically the number of peaks decreases with the increasing of the samples, 
allowing us to suddenly understand how many peaks we want to work with  
during the further analysis.

```{r}
## Create plot with number of peaks and "carriers" (Celltypes in this case)
grlct <- readRDS("RDS/grlct_celltypes_brain.RDS")
plotPeaksSamplesDEScan2(grlct)
```

## Computing Count Matrix 

Once we have the consensus peak list, we can finally construct the new 
count matrix with `countFinalRegions` function, passing as input the 
GR of the peaks and the directory of BAM files, producing as output a 
`SummarizedExperiment`.

```{r, eval=FALSE}

grlctSE <- lapply(seq_along(grlct), function(i)
{
    gr <- grlct[[i]]
    ct <- names(grlct)[i]
    
    message("Computing count final regions for ", ct)
    grSE <- countFinalRegions(gr, readsFilePath=metadata(gr)$bam_path,
                         fileType="bam", minCarriers=1)
    colnames(grSE) <- basename(colnames(grSE))
    grSE
})
names(grlctSE) <- names(grlct)
saveRDS(grlctSE, file="RDS/grlctSE_brain.RDS")
```

Just a brief look at the results

```{r}
grlctSE <- readRDS("RDS/grlctSE_brain.RDS")
assay(grlctSE[[1]])
rowRanges(grlctSE[[1]])
```

# Differential Accessible Regions Analysis

Because the previous dataset was only on a single condition, with two replicates
that are pratically the same sample, it was impossible to find Differential 
Accessible Regions.

To help investigate this aspect we are going to use another dataset from the
10x Genomics official website, with multiple already aggregated samples.

```{r}
library(HDF5Array)
library(scater)
library(RColorBrewer)
n <- 50
palette = brewer.pal.info[brewer.pal.info$category == 'qual',]
palette = unlist(mapply(brewer.pal, palette$maxcolors, rownames(palette)))
sce1 <- loadHDF5SummarizedExperiment("sce_Alzheimer_Ann_Tsn")
plotTSNE(sce1, colour_by="SingleR") + theme_bw() + scale_color_manual(values = palette)
plotTSNE(sce1, colour_by="condition") + theme_bw() 

library(darioscripts)
sce57aATAC <- readRDS("RDS/sce_alz_57_ps_ATAC.RDS")
sce57aATAC$replicate <- gsub("rep6", "rep3", sce57aATAC$replicate)
sce57aATAC$cnames <- paste0(sce57aATAC$SingleR, "_", sce57aATAC$genotype, "_" , sce57aATAC$replicate)
colnames(sce57aATAC) <- sce57aATAC$cnames

plotPCAs(counts(sce57aATAC),colData=colData(sce57aATAC), shapeBy="genotype", colorBy="SingleR")

sce57aATACct <- sce57aATAC[,sce57aATAC$SingleR=="Astro"]
plotPCAs(counts(sce57aATACct),colData=colData(sce57aATACct), shapeBy="genotype", colorBy="replicate")
```


## Normalization

We can try to normalize data to do a better comparison across the conditions, 
removing biases and improving the quality of the further differential analysis.

```{r}
library(RUVSeq)
gr <- makeGroups(sce57aATACct$genotype)
nn <- RUVs(counts(sce57aATACct), cIdx=rownames(sce57aATACct), k=1, scIdx=gr)
plotPCAs(nn$normalizedCounts, colData=colData(sce57aATACct), shapeBy="genotype", colorBy="replicate")  
sce57aATACct$RUVs_W <- nn$W
```

## Differential Analysis

We can now do the Differential Analysis by using edgeR, but as we can notice, 
there are no DARs between these two time-points.

```{r}
DARsdf <- applyEdgeR(counts(sce57aATACct), colData=colData(sce57aATACct), 
    factors="genotype", wnames="RUVs_W", contrasts="AD - WT", p.threshold=1)[[1]]
head(DARsdf)
```

## Another exaple

At this point we are interested in looking at the differences between celltypes
but at different time-points.

By comparing time-point 5.7 for the WT genotype with the 17.9 for the AD genotype.

As we can notice, there are very few DARs emerging, even when we are able to explain
a very high percentage of variance with the first Principal Component.
This highlights the very low number of DARs with this data.

```{r}
library(darioscripts)
sce57179aATAC <- readRDS("RDS/sce_alz_57_179_ps_ATAC.RDS")
sce57179aATAC$replicate <- gsub("rep4", "rep2", sce57179aATAC$replicate)
sce57179aATAC$replicate <- gsub("rep5", "rep3", sce57179aATAC$replicate)
sce57179aATAC$cnames <- paste0(sce57179aATAC$SingleR, "_", sce57179aATAC$genotype, "_" , sce57179aATAC$replicate)
colnames(sce57179aATAC) <- sce57179aATAC$cnames

plotPCAs(counts(sce57179aATAC),colData=colData(sce57179aATAC), shapeBy="genotype", colorBy="SingleR")+ scale_color_manual(values = palette)

sce57179aATACct <- sce57179aATAC[,sce57179aATAC$SingleR=="Oligo"]
plotPCAs(counts(sce57179aATACct),colData=colData(sce57179aATACct), shapeBy="genotype", colorBy="replicate")
```




```{r}
library(RUVSeq)
gr <- makeGroups(sce57179aATACct$gcondition)
nn <- RUVs(counts(sce57179aATACct), cIdx=rownames(sce57179aATACct), k=1, scIdx=gr)
# plotPCAs(nn$normalizedCounts, colData=colData(sce57179aATACct), shapeBy="genotype", colorBy="replicate")  
sce57179aATACct$RUVs_W <- nn$W
DARsdf <- applyEdgeR(counts(sce57179aATACct), colData=colData(sce57179aATACct), 
    factors="genotype", wnames="RUVs_W", contrasts="AD - WT", p.threshold=1)[[1]]
DARsdf[DARsdf$FDR<0.05,]
DARsdf$gene <- rownames(DARsdf)

PlotVolcanoPlot(DARsdf, as.data.frame(counts(sce57179aATACct)), 
                design.matrix=colData(sce57179aATACct), show.plot.flag=TRUE, threshold=0.1)
```


# MACS2 peaks

If we are not satisfied with cellranger-ARC peaks (emerged also with the number 
of detected DARs), as many authors suggests, we can take advantage of the MACS2 peak caller.

MACS2 is a widely used peak caller for bulk genomics data, it is a shell command
and it has functionalities for narrow and broad peaks.

Also in this case, because we want to construct pseudo-bulk like data for our ATAC
assays, we need to split the original cellranger BAM files in multiple BAM files, 
one per each cell type. (see section *Creating BAM files per cell types*)

We created an ad-hoc wrapper for working with MACS2 and previously constructed
BAM files taking a SingleCellExperiment as input.

```{r, eval=FALSE}

wrapMacs2 <- function(sce, outdir, genome="mm", nomodel="--nomodel", 
    extsize=200, shift=-(extsize/2), broadCall="--broad", bampath=NULL)
{
    stopifnot(is(sce, "SingleCellExperiment"))
    
    if(is.null(bampath)) bampath <- metadata(sce)$ct_bams 
    if(S4Vectors::isEmpty(bampath)) 
        stop("please provide a path for locating bam files!")
    
    bamfiles <- list.files(bampath, pattern="*_sorted.bam$", full.names=TRUE)
    bamfiles <- bamfiles[grep("ATAC", bamfiles)]
    if(isEmpty(bamfiles))
        stop("No BAM files detected in ", bampath)
    if(!dir.exists(outdir)) dir.create(outdir, recursive=TRUE)
    

    for(bfile in bamfiles)
    {
        cmd <- paste0("macs2 callpeak --treatment ", bfile, 
                    " --name ", basename(bfile), 
                    " --outdir ", outdir, 
                    " --format BAM --gsize ", genome, 
                    " ", nomodel,
                    " --extsize ", extsize,
                    " --shift ", shift,
                    " ", broadCall)
                    
        print(cmd)
        system(cmd)
    }
    
    ## read peaks for all the produced files, store the peaks in the rowRanges of sce
    ## add an extra column for the cell type
}
```


# Session Info

```{r, tidy=TRUE}
sessionInfo()
```






